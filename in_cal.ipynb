{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# InCal"
   ],
   "metadata": {
    "id": "67b041fc-2db1-4285-ab9c-3d2afd1dc98f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import pandas as pd\r\n",
    "import plotly.express as px\r\n",
    "import numpy as np\r\n",
    "from pandas.api.types import CategoricalDtype\r\n",
    "from IPython.display import display, HTML\r\n",
    "from statsmodels.formula.api import ols\r\n",
    "from collections import OrderedDict, Counter\r\n",
    "from jupyter_dash import JupyterDash \r\n",
    "from dash import html\r\n",
    "from dash import dcc\r\n",
    "import itertools\r\n",
    "from dash import no_update\r\n",
    "from dash import dash_table\r\n",
    "import dash\r\n",
    "from dash.dependencies import Input, Output"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0e6eec8-cecf-476a-a013-7a1a4fc54ec5",
    "outputId": "84b54fd2-3de5-4e89-c31d-3dc1fea1aea1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1 - **Upload data**\n",
    "\n",
    "run cell to upload the data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "6247bb01-08bd-4d8f-a91a-bfbca4c7acde"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "dataframes = {}\r\n",
    "is_one_file = True\r\n",
    "# 'this code block for the jupter colab only'\r\n",
    "# try:\r\n",
    "#     from google.colab import files\r\n",
    "#     import io\r\n",
    "#     uploaded = files.upload()\r\n",
    "#     if len(uploaded) > 1:\r\n",
    "#         for fn in uploaded.keys():\r\n",
    "#             print('User uploaded file \"{name}\" with length {length} bytes'.format(\r\n",
    "#                 name=fn, length=len(uploaded[fn])))\r\n",
    "#             dataframes[fn] = pd.read_csv(io.BytesIO(uploaded[fn]))\r\n",
    "#             is_one_file = False\r\n",
    "#     else:\r\n",
    "#         name = list(uploaded.keys())[0]\r\n",
    "#         dataframes = pd.read_csv(io.BytesIO(uploaded[name]))\r\n",
    "# except:\r\n",
    "#     print('check the if error - file.csv, there more then one table in the sheet?, is table has missing columns?')\r\n",
    "\r\n",
    "# dataframes = {\r\n",
    "#     '3': pd.read_csv(\"csvs/shani_exp/hebrew_2021-07-28_16_33_hebrew16_shani_w2_acdoors_pt1_m_calr.csv\", parse_dates=['Date_Time_1']),\r\n",
    "#     '4': pd.read_csv(\"csvs/shani_exp/hebrew_2021-08-01_13_49_hebrew16_shani_w1_pt2b_m_calr(1).csv\", parse_dates=['Date_Time_1']),\r\n",
    "#     '5': pd.read_csv(\"csvs/shani_exp/hebrew_2021-08-04_11_45_hebrew16_shani_acdoors_w2p1_m_calr.csv\", parse_dates=['Date_Time_1']),\r\n",
    "#     '6': pd.read_csv(\"csvs/all_weeks/hebrew_2021-08-10_16_15_hebrew16_shani_w2p2.1_m_calr.csv\", parse_dates=['Date_Time_1']),\r\n",
    "#     '7': pd.read_csv(\"csvs/all_weeks/hebrew_2021-08-11_16_24_hebrew16_shani_acdoors_w3_m_calr.csv\", parse_dates=['Date_Time_1']),\r\n",
    "#     '8': pd.read_csv(\"csvs/all_weeks/hebrew_2021-08-15_16_24_hebrew16_sahni_acdoors_w3p2_m_calr.csv\", parse_dates=['Date_Time_1']),\r\n",
    "#     '9': pd.read_csv(\"csvs/all_weeks/hebrew_2021-08-19_16_17_hebrew16_shani_acdoors_w4_m_calr.csv\", parse_dates=['Date_Time_1']),\r\n",
    "#     '10': pd.read_csv(\"csvs/all_weeks/hebrew_2021-08-26_16_12_hebrew16_shani_acdoors_w5_m_calr.csv\", parse_dates=['Date_Time_1']),\r\n",
    "#     '11': pd.read_csv(\"csvs/all_weeks/hebrew_2021-08-29_08_41_hebrew16_shani_acdoors_w5_dd_m_calr.csv\", parse_dates=['Date_Time_1']),\r\n",
    "#     '12': pd.read_csv(\"csvs/all_weeks/hebrew_2021-09-02_07_54_hebrew16_dark dark week2_m_calr.csv\", parse_dates=['Date_Time_1'])\r\n",
    "# }\r\n",
    "# dataframes = pd.read_csv('csvs\\shani_exp\\hebrew_2021-07-28_16_33_hebrew16_shani_w2_acdoors_pt1_m_calr.csv', parse_dates=['Date_Time_1'])\r\n",
    "dataframes = pd.read_csv('example_csvs/example.csv', parse_dates=['Date_Time_1'])\r\n",
    "dataframes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_Time_1</th>\n",
       "      <th>envirolightlux_2</th>\n",
       "      <th>envirotemp_2</th>\n",
       "      <th>envirorh_2</th>\n",
       "      <th>envirooccupancy_2</th>\n",
       "      <th>envirosound_2</th>\n",
       "      <th>vo2_1</th>\n",
       "      <th>vo2_2</th>\n",
       "      <th>vo2_3</th>\n",
       "      <th>vo2_4</th>\n",
       "      <th>...</th>\n",
       "      <th>allmeters_7</th>\n",
       "      <th>allmeters_8</th>\n",
       "      <th>allmeters_9</th>\n",
       "      <th>allmeters_10</th>\n",
       "      <th>allmeters_11</th>\n",
       "      <th>allmeters_12</th>\n",
       "      <th>allmeters_13</th>\n",
       "      <th>allmeters_14</th>\n",
       "      <th>allmeters_15</th>\n",
       "      <th>allmeters_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-28 16:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.421349</td>\n",
       "      <td>1.480283</td>\n",
       "      <td>2.206197</td>\n",
       "      <td>1.504177</td>\n",
       "      <td>...</td>\n",
       "      <td>2.371926</td>\n",
       "      <td>4.481019</td>\n",
       "      <td>4.337746</td>\n",
       "      <td>1.404414</td>\n",
       "      <td>3.553978</td>\n",
       "      <td>11.91558</td>\n",
       "      <td>3.425906</td>\n",
       "      <td>4.123155</td>\n",
       "      <td>8.667903</td>\n",
       "      <td>4.39023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-28 17:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.587630</td>\n",
       "      <td>1.730032</td>\n",
       "      <td>1.856729</td>\n",
       "      <td>1.248690</td>\n",
       "      <td>...</td>\n",
       "      <td>3.219805</td>\n",
       "      <td>12.191920</td>\n",
       "      <td>7.153311</td>\n",
       "      <td>2.106566</td>\n",
       "      <td>4.424401</td>\n",
       "      <td>16.35851</td>\n",
       "      <td>7.169481</td>\n",
       "      <td>5.093003</td>\n",
       "      <td>18.831850</td>\n",
       "      <td>11.94046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-28 17:25:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.824514</td>\n",
       "      <td>1.503004</td>\n",
       "      <td>1.637191</td>\n",
       "      <td>1.424713</td>\n",
       "      <td>...</td>\n",
       "      <td>3.219805</td>\n",
       "      <td>14.028540</td>\n",
       "      <td>7.280427</td>\n",
       "      <td>2.926421</td>\n",
       "      <td>5.007126</td>\n",
       "      <td>18.59064</td>\n",
       "      <td>8.205385</td>\n",
       "      <td>6.575711</td>\n",
       "      <td>27.916030</td>\n",
       "      <td>15.79637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-28 17:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.996406</td>\n",
       "      <td>1.523280</td>\n",
       "      <td>1.403817</td>\n",
       "      <td>1.462108</td>\n",
       "      <td>...</td>\n",
       "      <td>3.253144</td>\n",
       "      <td>14.028540</td>\n",
       "      <td>8.248654</td>\n",
       "      <td>4.176327</td>\n",
       "      <td>6.319085</td>\n",
       "      <td>21.97589</td>\n",
       "      <td>8.214393</td>\n",
       "      <td>8.115648</td>\n",
       "      <td>28.901700</td>\n",
       "      <td>16.33123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-28 18:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.707270</td>\n",
       "      <td>1.586915</td>\n",
       "      <td>2.213277</td>\n",
       "      <td>1.421148</td>\n",
       "      <td>...</td>\n",
       "      <td>4.968030</td>\n",
       "      <td>14.311580</td>\n",
       "      <td>11.172880</td>\n",
       "      <td>7.266493</td>\n",
       "      <td>6.572079</td>\n",
       "      <td>21.97760</td>\n",
       "      <td>8.400945</td>\n",
       "      <td>8.585472</td>\n",
       "      <td>28.938640</td>\n",
       "      <td>16.96868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2021-08-01 11:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.212794</td>\n",
       "      <td>1.064075</td>\n",
       "      <td>1.124583</td>\n",
       "      <td>1.102364</td>\n",
       "      <td>...</td>\n",
       "      <td>491.530700</td>\n",
       "      <td>633.174600</td>\n",
       "      <td>646.548500</td>\n",
       "      <td>531.221600</td>\n",
       "      <td>699.589700</td>\n",
       "      <td>1047.17600</td>\n",
       "      <td>452.942400</td>\n",
       "      <td>778.114700</td>\n",
       "      <td>762.586900</td>\n",
       "      <td>537.41680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>2021-08-01 12:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.236582</td>\n",
       "      <td>1.054845</td>\n",
       "      <td>1.897775</td>\n",
       "      <td>1.183671</td>\n",
       "      <td>...</td>\n",
       "      <td>491.648800</td>\n",
       "      <td>633.994800</td>\n",
       "      <td>646.972200</td>\n",
       "      <td>532.279500</td>\n",
       "      <td>699.589700</td>\n",
       "      <td>1050.29500</td>\n",
       "      <td>452.944200</td>\n",
       "      <td>782.722100</td>\n",
       "      <td>762.845100</td>\n",
       "      <td>537.72420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2021-08-01 12:25:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.308523</td>\n",
       "      <td>1.035974</td>\n",
       "      <td>1.897189</td>\n",
       "      <td>1.386340</td>\n",
       "      <td>...</td>\n",
       "      <td>491.720600</td>\n",
       "      <td>635.166900</td>\n",
       "      <td>648.094000</td>\n",
       "      <td>532.339700</td>\n",
       "      <td>699.589700</td>\n",
       "      <td>1050.35100</td>\n",
       "      <td>452.947800</td>\n",
       "      <td>785.962900</td>\n",
       "      <td>764.462200</td>\n",
       "      <td>537.88200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2021-08-01 12:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.162044</td>\n",
       "      <td>1.128753</td>\n",
       "      <td>1.476144</td>\n",
       "      <td>1.171823</td>\n",
       "      <td>...</td>\n",
       "      <td>491.814000</td>\n",
       "      <td>635.210900</td>\n",
       "      <td>648.141800</td>\n",
       "      <td>532.339700</td>\n",
       "      <td>700.710300</td>\n",
       "      <td>1050.38200</td>\n",
       "      <td>453.189300</td>\n",
       "      <td>785.962900</td>\n",
       "      <td>764.494900</td>\n",
       "      <td>538.84810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2021-08-01 13:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.237399</td>\n",
       "      <td>1.073596</td>\n",
       "      <td>1.098089</td>\n",
       "      <td>1.222708</td>\n",
       "      <td>...</td>\n",
       "      <td>492.712600</td>\n",
       "      <td>635.210900</td>\n",
       "      <td>648.265900</td>\n",
       "      <td>532.339700</td>\n",
       "      <td>703.227300</td>\n",
       "      <td>1050.46600</td>\n",
       "      <td>453.458600</td>\n",
       "      <td>785.962900</td>\n",
       "      <td>764.542100</td>\n",
       "      <td>541.53670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date_Time_1  envirolightlux_2  envirotemp_2  envirorh_2  \\\n",
       "0   2021-07-28 16:45:00                 0             0           0   \n",
       "1   2021-07-28 17:05:00                 0             0           0   \n",
       "2   2021-07-28 17:25:00                 0             0           0   \n",
       "3   2021-07-28 17:45:00                 0             0           0   \n",
       "4   2021-07-28 18:05:00                 0             0           0   \n",
       "..                  ...               ...           ...         ...   \n",
       "273 2021-08-01 11:45:00                 0             0           0   \n",
       "274 2021-08-01 12:05:00                 0             0           0   \n",
       "275 2021-08-01 12:25:00                 0             0           0   \n",
       "276 2021-08-01 12:45:00                 0             0           0   \n",
       "277 2021-08-01 13:05:00                 0             0           0   \n",
       "\n",
       "     envirooccupancy_2  envirosound_2     vo2_1     vo2_2     vo2_3     vo2_4  \\\n",
       "0                    0              0  1.421349  1.480283  2.206197  1.504177   \n",
       "1                    0              0  1.587630  1.730032  1.856729  1.248690   \n",
       "2                    0              0  1.824514  1.503004  1.637191  1.424713   \n",
       "3                    0              0  1.996406  1.523280  1.403817  1.462108   \n",
       "4                    0              0  1.707270  1.586915  2.213277  1.421148   \n",
       "..                 ...            ...       ...       ...       ...       ...   \n",
       "273                  0              0  1.212794  1.064075  1.124583  1.102364   \n",
       "274                  0              0  1.236582  1.054845  1.897775  1.183671   \n",
       "275                  0              0  1.308523  1.035974  1.897189  1.386340   \n",
       "276                  0              0  1.162044  1.128753  1.476144  1.171823   \n",
       "277                  0              0  1.237399  1.073596  1.098089  1.222708   \n",
       "\n",
       "     ...  allmeters_7  allmeters_8  allmeters_9  allmeters_10  allmeters_11  \\\n",
       "0    ...     2.371926     4.481019     4.337746      1.404414      3.553978   \n",
       "1    ...     3.219805    12.191920     7.153311      2.106566      4.424401   \n",
       "2    ...     3.219805    14.028540     7.280427      2.926421      5.007126   \n",
       "3    ...     3.253144    14.028540     8.248654      4.176327      6.319085   \n",
       "4    ...     4.968030    14.311580    11.172880      7.266493      6.572079   \n",
       "..   ...          ...          ...          ...           ...           ...   \n",
       "273  ...   491.530700   633.174600   646.548500    531.221600    699.589700   \n",
       "274  ...   491.648800   633.994800   646.972200    532.279500    699.589700   \n",
       "275  ...   491.720600   635.166900   648.094000    532.339700    699.589700   \n",
       "276  ...   491.814000   635.210900   648.141800    532.339700    700.710300   \n",
       "277  ...   492.712600   635.210900   648.265900    532.339700    703.227300   \n",
       "\n",
       "     allmeters_12  allmeters_13  allmeters_14  allmeters_15  allmeters_16  \n",
       "0        11.91558      3.425906      4.123155      8.667903       4.39023  \n",
       "1        16.35851      7.169481      5.093003     18.831850      11.94046  \n",
       "2        18.59064      8.205385      6.575711     27.916030      15.79637  \n",
       "3        21.97589      8.214393      8.115648     28.901700      16.33123  \n",
       "4        21.97760      8.400945      8.585472     28.938640      16.96868  \n",
       "..            ...           ...           ...           ...           ...  \n",
       "273    1047.17600    452.942400    778.114700    762.586900     537.41680  \n",
       "274    1050.29500    452.944200    782.722100    762.845100     537.72420  \n",
       "275    1050.35100    452.947800    785.962900    764.462200     537.88200  \n",
       "276    1050.38200    453.189300    785.962900    764.494900     538.84810  \n",
       "277    1050.46600    453.458600    785.962900    764.542100     541.53670  \n",
       "\n",
       "[278 rows x 198 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "1f090fc2-f59c-4546-9e11-3037b35f20b9",
    "outputId": "a05acf8c-c723-4ed7-f5ae-6404de1d2fd0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2 - **INSERT EXPERIMENT DATA**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "f83b5852-9792-4dcb-9798-5e1d20ad31ab"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "dict_groups = OrderedDict(Control = [1, 4, 7, 10, 13], Group_2 = [3, 5, 9, 12, 16], Group_3 = [2, 6, 8, 11, 14, 15])\r\n",
    "print(f\"{dict_groups}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OrderedDict([('Control', [1, 4, 7, 10, 13]), ('Group_2', [3, 5, 9, 12, 16]), ('Group_3', [2, 6, 8, 11, 14, 15])])\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2569ff91-31bc-42f2-a1e3-c9c99113f905",
    "outputId": "c835c165-5315-4891-d023-b8f4d93ecc28"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## names replacement\n",
    "\n",
    "..."
   ],
   "metadata": {
    "id": "r3WGpfUKRK5K"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "name_for_replacement_in_data_table = {\r\n",
    "    'bodymass': 'Weight_(gr)', \r\n",
    "    'vo2': 'Oxygen_Consumption_(ml/hr)', \r\n",
    "    'vco2': 'Carbon_Dioxide_Production_(ml/hr)',\r\n",
    "    'kcal_hr': 'Energy_Expenditure_(kcal/hour)',\r\n",
    "    'foodupa': 'Cumulative_Food_Intake_(kcal)',\r\n",
    "    'rq': 'Respiratory_Exchange_Ratio',\r\n",
    "    'pedmeters': 'Pedestrian_Locomotion_(m)',\r\n",
    "    'allmeters': 'Total_Distance_includes_fine_movement_(m)',\r\n",
    "    'waterupa': 'Cumulative_Water_Intake_(ml)',\r\n",
    "    'Wheel': 'Total_Wheel_Counts_(Counts)' # need to check about the wheel parme...\r\n",
    "}\r\n",
    "\r\n",
    "calculeted_parmeters = {\r\n",
    "    'water': 'Hourly_Water_Intake_(ml)',   \r\n",
    "    'food': 'Hourly_Food_Intake_(kcal)',\r\n",
    "    'locomotor_activity': 'Locomotor_Activity_(beam_breaks)',\r\n",
    "    'energy_balance': 'Energy_Balance_(kcal/hour)',\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "id": "04a71bd1-c0d7-4b01-992b-f3dcff2d27a3",
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Prepring the data**"
   ],
   "metadata": {
    "id": "63dacdf1-e490-44d2-ac66-d91f2130223a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions for Prepring\r\n",
    "\r\n",
    "-> run cell"
   ],
   "metadata": {
    "id": "65752f80-7200-4829-92c6-5a085e5e74d5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# removing subjects or group\r\n",
    "def get_values_level(df, number_or_index_name):\r\n",
    "  return df.index.get_level_values(number_or_index_name)\r\n",
    "\r\n",
    "def get_difference_from_list_2(list1, list2):\r\n",
    "    return list(set(list1) - set(list2))\r\n",
    "\r\n",
    "def incal_remove_subjects(df, number_or_index_name, subjects_to_remove):\r\n",
    "  subjects = get_values_level(df, number_or_index_name)\r\n",
    "  strs_to_ints = lambda l: [int(x) for x in l]\r\n",
    "  subjects_to_remove_ints = strs_to_ints(subjects_to_remove)\r\n",
    "  selected_subjects = get_difference_from_list_2(subjects, subjects_to_remove_ints)\r\n",
    "  return df.loc[:, selected_subjects , :]\r\n",
    "\r\n",
    "def incal_remove_group(df, number_or_index_name, groups_to_remove):\r\n",
    "  subjects = get_values_level(df, number_or_index_name)\r\n",
    "  selected_group = get_difference_from_list_2(subjects, groups_to_remove)\r\n",
    "  return df.loc[:, : , selected_group]\r\n",
    "\r\n",
    "# removing outliears\r\n",
    "def sort_data_by_ids(df, column_name):\r\n",
    "    return df.sort_values(column_name)\r\n",
    "\r\n",
    "def flat_list(d_list):\r\n",
    "    '''\r\n",
    "    dependencies: itertools\r\n",
    "    '''\r\n",
    "    return list(itertools.chain.from_iterable(d_list))\r\n",
    "\r\n",
    "def slice_df_for_floats_and_category(df, column_name):\r\n",
    "    return df.select_dtypes(include=['float64']), df.select_dtypes(include=['category'])\r\n",
    "\r\n",
    "def get_subject_ids(df, column_name):\r\n",
    "    return df[column_name].unique()\r\n",
    "\r\n",
    "def calc_mean_and_std_for_df_by_ids(df, ids_column_name):\r\n",
    "    return df.groupby(ids_column_name).agg([np.mean, np.std])\r\n",
    "\r\n",
    "def get_lims_upper_and_lower(df_means_and_stds, number_of_ids, number_featuers_columns, by_sd_of=2):\r\n",
    "    calcs_shape_values = df_means_and_stds.values.reshape(number_of_ids, number_featuers_columns, 2)\r\n",
    "    means = calcs_shape_values[:, :, :1]\r\n",
    "    stds = calcs_shape_values[:, :, 1:]\r\n",
    "    upper_lims = means + stds * by_sd_of\r\n",
    "    lower_lims = means - stds * by_sd_of\r\n",
    "    return upper_lims, lower_lims\r\n",
    "\r\n",
    "def reshpe_vlaues_3d_ndarray(ndarray, axis0_dimensions, axis1_columns, axis2_rows):\r\n",
    "    return ndarray.reshape(axis0_dimensions, axis1_columns, axis2_rows)\r\n",
    "\r\n",
    "def select_and_replace_outliers(ndarry_of_features, ndarry_uppers_lims, ndarry_lowers_lims):\r\n",
    "    conditiones = [\r\n",
    "        ndarry_of_features > ndarry_uppers_lims,\r\n",
    "        ndarry_of_features < ndarry_lowers_lims\r\n",
    "    ]\r\n",
    "    choices = [np.nan, np.nan]\r\n",
    "    return np.select(conditiones, choices, ndarry_of_features)\r\n",
    "    \r\n",
    "def back_to_2d_ndarray(ndarry_of_features, axis1, axis2):\r\n",
    "    return ndarry_of_features.reshape(axis1, axis2)\r\n",
    "    \r\n",
    "def sort_data_by_index(df):\r\n",
    "    return df.sort_index()\r\n",
    "\r\n",
    "def get_categories_cals_names(df):\r\n",
    "    return df.index.names[1:] \r\n",
    "\r\n",
    "def incal_get_categories_col_from_multiindex(df):\r\n",
    "  levels_names = get_categories_cals_names(df)\r\n",
    "  get_values_values_from_index = df.reset_index(level=levels_names)\r\n",
    "  return get_values_values_from_index[levels_names]\r\n",
    "\r\n",
    "def remove_outliers_mixed_df(df, column_ids_name):\r\n",
    "    sorted_df = sort_data_by_ids(df, column_ids_name)\r\n",
    "    fetuers, ids = slice_df_for_floats_and_category(sorted_df, column_ids_name)\r\n",
    "    df_means_and_stds = calc_mean_and_std_for_df_by_ids(fetuers, ids[column_ids_name])\r\n",
    "    number_of_ids = len(ids[column_ids_name].unique())\r\n",
    "    fetuers_columns = fetuers.columns\r\n",
    "    number_featuers_columns = len(fetuers_columns)\r\n",
    "    upper_lims, lower_lims = get_lims_upper_and_lower(df_means_and_stds, number_of_ids, number_featuers_columns)\r\n",
    "    dimensions_by_numbers_of_ids_upper_lims = reshpe_vlaues_3d_ndarray(upper_lims, number_of_ids, 1, number_featuers_columns) \r\n",
    "    dimensions_by_numbers_of_ids_lower_lims = reshpe_vlaues_3d_ndarray(lower_lims, number_of_ids, 1, number_featuers_columns)\r\n",
    "    columns_of_each_id = fetuers.shape[0] // number_of_ids\r\n",
    "    dimensions_by_numbers_of_ids_values = reshpe_vlaues_3d_ndarray(\r\n",
    "        fetuers.values, \r\n",
    "        number_of_ids, \r\n",
    "        columns_of_each_id, \r\n",
    "        number_featuers_columns\r\n",
    "    )\r\n",
    "    outliers_replaced_to_nan_values_ndarray = select_and_replace_outliers(\r\n",
    "        dimensions_by_numbers_of_ids_values, \r\n",
    "        dimensions_by_numbers_of_ids_upper_lims, \r\n",
    "        dimensions_by_numbers_of_ids_lower_lims\r\n",
    "        )\r\n",
    "    combien_axis0_and_axis1 = number_of_ids * columns_of_each_id\r\n",
    "    original_df_shape = back_to_2d_ndarray(outliers_replaced_to_nan_values_ndarray, combien_axis0_and_axis1, number_featuers_columns)\r\n",
    "    df_fetuers_without_outliers = pd.DataFrame(original_df_shape, columns=fetuers_columns, index=ids.index)\r\n",
    "    df_without_outliers = pd.concat([ids, df_fetuers_without_outliers], axis=1)\r\n",
    "    return sort_data_by_index(df_without_outliers)\r\n",
    "# 17.1 ms ± 175 µs per loop (mean ± std. dev. of 5 runs, 100 loops each)\r\n",
    "\r\n",
    "def select_columns_by_metebolic_parm(df, param_name, exclude=False):\r\n",
    "    if exclude == True:\r\n",
    "        mask = ~df.columns.str.contains(pat=param_name)\r\n",
    "        return df.loc[:, mask]\r\n",
    "    mask = df.columns.str.contains(pat=param_name)\r\n",
    "    return df.loc[:, mask]\r\n",
    "\r\n",
    "def selecting_multi_column_by_part_of_name(df, list_pattern_parm):\r\n",
    "    return df.filter(regex='|'.join(list_pattern_parm))\r\n",
    "\r\n",
    "def multi_columns_by_metabolic_param(df, list_met_param, number):\r\n",
    "    # https://stackoverflow.com/questions/21285380/find-column-whose-name-contains-a-specific-string\r\n",
    "    columns_for_calc = df.columns[df.columns.astype(\"string\").str.contains(pat=\"|\".join(list_met_param))]\r\n",
    "    df_calc = df[columns_for_calc].apply(lambda x: x * number)\r\n",
    "    drop_old_columns = df.drop(columns_for_calc, axis=1)\r\n",
    "    return pd.concat([drop_old_columns, df_calc], axis=1)\r\n",
    "\r\n",
    "def loop_func_and_dfs(dfs, func, *args):\r\n",
    "    return [func(df, *args) for df in dfs]\r\n",
    "\r\n",
    "def _get_columns_names_list(df):\r\n",
    "    return df.columns.values.tolist()\r\n",
    "\r\n",
    "def _make_dict_to_replace_names(columns_names_list, pattern_addition_to_parms):\r\n",
    "    leng = len(columns_names_list)\r\n",
    "    return {columns_names_list[i]: pattern_addition_to_parms + columns_names_list[i] for i in range(leng)}\r\n",
    "\r\n",
    "def _get_actuals_values(df):\r\n",
    "    df_actuals_features_calculeted = df.diff()\r\n",
    "    first_row_df_cumuletive = df.iloc[0:1]\r\n",
    "    return df_actuals_features_calculeted.fillna(first_row_df_cumuletive)\r\n",
    "\r\n",
    "def incal_get_actuals_from_cumuletive(df, columns_pattern, pattern_addition_to_parms):\r\n",
    "    # get just the cumuletive columns from the original df\r\n",
    "    df_cumuletive_culumns = select_columns_by_metebolic_parm(df, columns_pattern)\r\n",
    "    # get the columns names of the cumuletive columns\r\n",
    "    columns_names = _get_columns_names_list(df_cumuletive_culumns)\r\n",
    "    # dict to replace names\r\n",
    "    dict_new_names = _make_dict_to_replace_names(columns_names, pattern_addition_to_parms)\r\n",
    "    # replace the columns names of the actuals culumns\r\n",
    "    df_actuals_features = df_cumuletive_culumns.rename(columns=dict_new_names)\r\n",
    "    df_actuals = _get_actuals_values(df_actuals_features)\r\n",
    "    return pd.concat([df, df_actuals], axis=1).drop(columns_names, axis=1)\r\n",
    "\r\n",
    "def incal_calc_cumuletive_values(df, columns_pattern):\r\n",
    "    select_cols = df.columns.astype(\"string\").str.contains(pat = columns_pattern)\r\n",
    "    actuals = df.loc[:, select_cols]\r\n",
    "    actuals_columns_names = actuals.columns.values.tolist()\r\n",
    "    new_cols_names = [name.replace(columns_pattern, '') for name in actuals_columns_names]\r\n",
    "    langth = len(actuals_columns_names)\r\n",
    "    cumuletive = actuals.rename(columns={actuals_columns_names[i]: new_cols_names[i] for i in range(langth)}).cumsum()\r\n",
    "    return pd.concat([df, cumuletive], axis=1)\r\n",
    "\r\n",
    "def incal_set_multindex(df, list_of_multi_index):\r\n",
    "  ids_indexed_df = df.reset_index()\r\n",
    "  return ids_indexed_df.set_index(list_of_multi_index)\r\n",
    "  \r\n",
    "def incal_groupby_then_agg(df, list_to_groupby, agg_func):\r\n",
    "    groupby = df.groupby(list_to_groupby)\r\n",
    "    return groupby.agg(agg_func)\r\n",
    "\r\n",
    "def incal_resample(df_unstacked_subjects, role_to_resmple_by, agg_func):\r\n",
    "    # refactoring - > make it more genric function\r\n",
    "  # https://stackoverflow.com/questions/15799162/resampling-within-a-pandas-multiindex\r\n",
    "  return incal_groupby_then_agg(\r\n",
    "                df_unstacked_subjects, \r\n",
    "                [\r\n",
    "                    pd.Grouper(level='Date_Time_1', freq=role_to_resmple_by), \r\n",
    "                    pd.Grouper(level='subjectID')\r\n",
    "                ], \r\n",
    "                agg_func)\r\n",
    "\r\n",
    "def _multi_index_df_unstack(df_multi_indexed):\r\n",
    "  return df_multi_indexed.unstack()\r\n",
    "\r\n",
    "def _return_original_stacked_df(df_unstacked_subjects):\r\n",
    "  return df_unstacked_subjects.stack().reset_index(level=1)\r\n",
    "\r\n",
    "def incal_cumsum(df, list_of_multi_index, list_columns_names_to_cumsum):\r\n",
    "  multi_indexed_df = incal_set_multindex(df, list_of_multi_index)\r\n",
    "  unstacked_df = _multi_index_df_unstack(multi_indexed_df)\r\n",
    "  cumsum_columns = unstacked_df[list_columns_names_to_cumsum].cumsum()\r\n",
    "  cumsum_columns.columns = cumsum_columns.columns.map(lambda s: (s[0] + '_cumsum', s[1])) \r\n",
    "  concat_cumsum_columns = pd.concat([unstacked_df, cumsum_columns], axis=1)\r\n",
    "  return _return_original_stacked_df(concat_cumsum_columns)\r\n",
    "\r\n",
    "def _right_sepert_first_underscore(string):\r\n",
    "    return tuple(string.rsplit(\"_\", 1))\r\n",
    "\r\n",
    "def _assemble_multi_index_axis_1_df(df, d_list, axis_1_names=[\"\", \"\"]):\r\n",
    "    # make a multi index \r\n",
    "    mul_i_columns = pd.MultiIndex.from_tuples(d_list, names=axis_1_names)\r\n",
    "    # assemble new dataframe with multi index columns  \r\n",
    "    return pd.DataFrame(df.values, index=df.index, columns=mul_i_columns)\r\n",
    "    # then stack level 1 to the columns (level 1 -> subjects names e.g. 1 2 3...)\r\n",
    "\r\n",
    "def incal_wide_to_long_df(wide_df, col_subj_name='subjectID'):\r\n",
    "    cols_names = _get_columns_names_list(wide_df)\r\n",
    "    # sepert feature name from cage number and put it in a tuple together ('allmeters', '1')\r\n",
    "    l_micolumns  = [_right_sepert_first_underscore(col) for col in cols_names]\r\n",
    "    multi_index_axis_1_df = _assemble_multi_index_axis_1_df(\r\n",
    "        wide_df, \r\n",
    "        l_micolumns, \r\n",
    "        ['', col_subj_name]\r\n",
    "    )\r\n",
    "    # https://pandas.pydata.org/docs/user_guide/reshaping.html\r\n",
    "    return multi_index_axis_1_df.stack(level=1)\r\n",
    "\r\n",
    "def flatten(lst_in_lst):\r\n",
    "    lst = []\r\n",
    "    for l in lst_in_lst:\r\n",
    "        if type(l) in [list,tuple,set]:\r\n",
    "            lst.extend(l)\r\n",
    "        else:\r\n",
    "            return lst_in_lst\r\n",
    "    return lst\r\n",
    "\r\n",
    "def order_categoreis_columns(df, **kargs):\r\n",
    "    '''\r\n",
    "    order_categoreis_columns make sure the group and subjects in the right order. This is for,\r\n",
    "    the statiscal analysis. The groups and the subjects needs to be in order of the expriment design.\r\n",
    "    In order the anova, ancova and anova with interaction to work properly\r\n",
    "    \r\n",
    "    '''\r\n",
    "    for col_name, order in kargs.items():\r\n",
    "        df[col_name] = pd.Categorical(df[col_name], ordered=True, categories=flatten(order))\r\n",
    "        \r\n",
    "def day_and_night(df, datetime_column='Date_Time_1', start=7, end=19):\r\n",
    "    df = df.assign(\r\n",
    "        time=lambda x: np.where(\r\n",
    "          df[datetime_column].dt.hour.ge(start) \r\n",
    "          & df[datetime_column].dt.hour.lt(end), 'Day', 'Night')).dropna()\r\n",
    "    return df\r\n",
    "\r\n",
    "def incal_make_averages_table(df, columns_names_too_groupby=['Group', 'subjectID'], column_name_for_time_of_day='time'):\r\n",
    "    full_day = df.groupby(by=columns_names_too_groupby, sort=True, dropna=True).mean().reset_index().dropna()\r\n",
    "    full_day[column_name_for_time_of_day] = 'Full day'\r\n",
    "    D_and_N_df = day_and_night(df).groupby(by=[column_name_for_time_of_day, *columns_names_too_groupby], sort=True, dropna=True).mean().reset_index().dropna()\r\n",
    "    return pd.concat([full_day, D_and_N_df])\r\n",
    "\r\n",
    "# day and night time this data use for the graph below\r\n",
    "def make_lists_start_and_end_to_day_night_time(df, datetime64_column='Date_Time_1', start=7, end=19):\r\n",
    "    array_data_list = df[datetime64_column].unique()\r\n",
    "    Series_datetime64 = pd.Series(array_data_list, name=datetime64_column)\r\n",
    "    mask_daylight = Series_datetime64.dt.hour.ge(start) & Series_datetime64.dt.hour.lt(end)\r\n",
    "    start_end = []\r\n",
    "    still_True = False\r\n",
    "    for i in range(len(Series_datetime64)):\r\n",
    "        if still_True and mask_daylight.iloc[i]:\r\n",
    "            start_end.append(Series_datetime64.iloc[i])\r\n",
    "            still_True = False\r\n",
    "        elif not still_True and not mask_daylight.iloc[i]:\r\n",
    "            start_end.append(Series_datetime64.iloc[i])\r\n",
    "            still_True = True\r\n",
    "    return start_end\r\n",
    "\r\n",
    "# stats\r\n",
    "anova_features = [\r\n",
    "  'rq', \r\n",
    "  'locomotor_activity', \r\n",
    "  'actual_pedmeters_cumsum', \r\n",
    "  'actual_allmeters_cumsum'\r\n",
    "]\r\n",
    "ancova_and_anova_with_interaction_features = [\r\n",
    "  'Energy_Balance', \r\n",
    "  'kcal_hr',\r\n",
    "  'vo2', \r\n",
    "  'vco2', \r\n",
    "  'actual_foodupa', \r\n",
    "  'actual_waterupa', \r\n",
    "  ]\r\n",
    "\r\n",
    "def reanem_df_by_with_list_by_index(df, indexed_new_names):\r\n",
    "  columns_names = df.columns.values.tolist()\r\n",
    "  new_columns_names = indexed_new_names\r\n",
    "  zip_lists = zip(columns_names, new_columns_names)\r\n",
    "  dict_renamed_columns = {column_name: new_column_name for column_name, new_column_name in zip_lists}\r\n",
    "  return df.rename(columns=dict_renamed_columns)\r\n",
    "\r\n",
    "def concat_dfs(list_of_series_dfs):\r\n",
    "  return pd.concat(list_of_series_dfs, axis=1)\r\n",
    "\r\n",
    "def anova_with_interaction(df, metabolic_var, independent, categorical):\r\n",
    "    return ols(f'{metabolic_var} ~ {independent} + C({categorical}) + {independent}:C({categorical})', data=df).fit().pvalues\r\n",
    "def ancova(df, metabolic_var, independent, categorical):\r\n",
    "    return ols(f'{metabolic_var} ~ {independent} + C({categorical})', data=df).fit().pvalues\r\n",
    "def anova(df, metabolic_var, categorical):\r\n",
    "    return ols(f'{metabolic_var} ~ C({categorical})', data=df).fit().pvalues\r\n",
    "\r\n",
    "def make_pvalues_of_anova_analysis(df, m_vars, cat_var):\r\n",
    "  return [anova(df, m_var, cat_var) for m_var in m_vars]\r\n",
    "def make_pvalues_of_ancova_analysis(df, m_vars, independent, cat_var):\r\n",
    "  return [ancova(df, m_var, independent, cat_var) for m_var in m_vars]\r\n",
    "def make_pvalues_of_anova_with_interaction_analysis(df, m_vars, independent, cat_var):\r\n",
    "  return [anova_with_interaction(df, m_var, independent, cat_var) for m_var in m_vars]\r\n",
    "\r\n",
    "def match_case(case, df, list_of_features, independent, category_col_name):\r\n",
    "  cases = {\r\n",
    "    'anova': make_pvalues_of_anova_analysis(\r\n",
    "                                df, \r\n",
    "                                list_of_features, \r\n",
    "                                category_col_name\r\n",
    "                                ),\r\n",
    "    'ancova': make_pvalues_of_ancova_analysis(\r\n",
    "                    df, \r\n",
    "                    list_of_features, \r\n",
    "                    independent,\r\n",
    "                    category_col_name\r\n",
    "                    ), \r\n",
    "    'anova_with_interaction': make_pvalues_of_anova_with_interaction_analysis(\r\n",
    "                    df, \r\n",
    "                    list_of_features, \r\n",
    "                    independent,\r\n",
    "                    category_col_name\r\n",
    "                    ), \r\n",
    "    \r\n",
    "  }\r\n",
    "  return cases[case]\r\n",
    "\r\n",
    "def incal_create_pvalues_datafram(case, df, list_of_features, independent, category_col_name):\r\n",
    "  results_from_anovafunction = match_case(case, df, list_of_features, independent, category_col_name)\r\n",
    "  pvalues_dfs_concated = concat_dfs(results_from_anovafunction)\r\n",
    "  return reanem_df_by_with_list_by_index(pvalues_dfs_concated, list_of_features)\r\n",
    "\r\n",
    "def create_anovas_table(df):\r\n",
    "    anova_df = incal_create_pvalues_datafram(\r\n",
    "    'anova', \r\n",
    "    df, \r\n",
    "    anova_features, \r\n",
    "    'bodymass',\r\n",
    "    'Group'\r\n",
    "    )\r\n",
    "    anova_with_interaction_df = incal_create_pvalues_datafram(\r\n",
    "    'anova_with_interaction', \r\n",
    "    df, \r\n",
    "    ancova_and_anova_with_interaction_features, \r\n",
    "    'bodymass',\r\n",
    "    'Group'\r\n",
    "    )\r\n",
    "    # algoritem that get each non p value in anova with interaction and replace it with anova values and fill nan where is needed\r\n",
    "    ancova_df = incal_create_pvalues_datafram(\r\n",
    "    'ancova', \r\n",
    "    df, \r\n",
    "    ancova_and_anova_with_interaction_features, \r\n",
    "    'bodymass',\r\n",
    "    'Group'\r\n",
    "    )\r\n",
    "    return concat_dfs([anova_df, anova_with_interaction_df, ancova_df]).T"
   ],
   "outputs": [],
   "metadata": {
    "id": "e792c676-386a-4305-a69c-927614fa91a3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Insert experimental design"
   ],
   "metadata": {
    "id": "b26e5abd-7c4a-4423-abc5-d0191dcef2bd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "unwanted_column = \"|\".join(['envirolightlux', 'envirooccupancy', 'envirorh', 'envirosound', 'envirotemp'])\r\n",
    "cumulative_parm = \"|\".join(['food', 'water', 'allmeters', 'wheelmeters', 'pedmeters'])\r\n",
    "not_for_use_columns = ['vh2o', 'xbreak', 'ybreak', 'index'] # do nothig with it becouse it not importent to delete now this columns\r\n",
    "pattern_addition_to_parms = 'actual_'\r\n",
    "regx_pattern_for_mean = 'vo2|vco2|vh2o|rq_|bodymass|rq|kcal_hr|break_'\r\n",
    "regx_pattern_for_sum = 'water|food'\r\n",
    "\r\n",
    "dict_aggrageted_function_for_column = {\r\n",
    "  'Energy_Balance': 'mean',\r\n",
    "  'actual_allmeters': 'mean',\r\n",
    "  'actual_pedmeters': 'mean',\r\n",
    "  'bodymass': 'mean',\r\n",
    "  'kcal_hr': 'mean',\r\n",
    "  'locomotor_activity': 'mean',\r\n",
    "  'rq': 'mean',\r\n",
    "  'vco2': 'mean',\r\n",
    "  'vo2': 'mean',\r\n",
    "  'vh2o': 'mean',\r\n",
    "  'xbreak': 'mean',\r\n",
    "  'ybreak': 'mean',\r\n",
    "  'actual_foodupa': 'sum', \r\n",
    "  'actual_waterupa': 'sum',\r\n",
    "}\r\n",
    "regx_pattern_no_mean_or_sum = regx_pattern_for_sum + regx_pattern_for_mean"
   ],
   "outputs": [],
   "metadata": {
    "id": "IQIQYAm1TeDT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Make analysis table**"
   ],
   "metadata": {
    "id": "qpBSfmPMUXBU"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Merge files!!\r\n",
    "df_or_dfs_in_list = [dataframes] if is_one_file else dataframes.values()\r\n",
    "dfs = [incal_get_actuals_from_cumuletive(df, cumulative_parm, pattern_addition_to_parms) for df in df_or_dfs_in_list]\r\n",
    "dfs_concated = pd.concat(dfs)\r\n",
    "\r\n",
    "dfs_concated_cleaned = select_columns_by_metebolic_parm(dfs_concated, unwanted_column, True) \r\n",
    "\r\n",
    "dfs_concated = incal_set_multindex(dfs_concated, ['Date_Time_1']).drop(columns='index')\r\n",
    "analysis_format = incal_wide_to_long_df(dfs_concated)\r\n",
    "\r\n",
    "analysis_format[['vco2', 'vh2o', 'vo2']] = analysis_format[['vco2', 'vh2o', 'vo2']].mul(60)\r\n",
    "analysis_format[['actual_foodupa']] = analysis_format[['actual_foodupa']].mul(3.56)\r\n",
    "analysis_format['Energy_Balance'] = analysis_format['actual_foodupa'].values - analysis_format['kcal_hr'].values\r\n",
    "analysis_format['locomotor_activity'] = analysis_format[['xbreak', 'ybreak']].sum(axis=1)\r\n",
    "\r\n",
    "resampled_analysis_format = incal_resample(analysis_format, 'H', dict_aggrageted_function_for_column)\r\n",
    "\r\n",
    "featuers_to_cumsum_by = ['actual_pedmeters', 'actual_allmeters']\r\n",
    "analysis_format = incal_cumsum(analysis_format, ['Date_Time_1', 'subjectID'], featuers_to_cumsum_by)\r\n",
    "resampled_analysis_format = incal_cumsum(resampled_analysis_format, ['Date_Time_1', 'subjectID'], featuers_to_cumsum_by)\r\n",
    "\r\n",
    "add_feature_for_agg = {\r\n",
    "  **dict_aggrageted_function_for_column, \r\n",
    "  'actual_allmeters_cumsum': 'mean',\r\n",
    "  'actual_pedmeters_cumsum': 'mean'\r\n",
    "}\r\n",
    "\r\n",
    "# analysis format - with original datetime samples\r\n",
    "incal_create_groups_column(resampled_analysis_format, dict_groups, 'subjectID')\r\n",
    "resampled_analysis_format = incal_set_multindex(resampled_analysis_format, ['Date_Time_1', 'subjectID', 'Group']) \r\n",
    "# analysis format - datetime agg hor each rol\r\n",
    "incal_create_groups_column(resampled_analysis_format.reset_index(level=1), dict_groups, 'subjectID')\r\n",
    "resampled_analysis_format = incal_set_multindex(resampled_analysis_format, ['Date_Time_1', 'subjectID', 'Group']) \r\n",
    "# analysis format - averages for each subject\r\n",
    "analysis_format_indexed = incal_set_multindex(resampled_analysis_format, ['Date_Time_1', 'subjectID', 'Group'])\r\n",
    "grouped_analysis_format_df = analysis_format_indexed.groupby(level=['subjectID', 'Group'])\r\n",
    "analysis_format_calculeted = grouped_analysis_format_df.agg(add_feature_for_agg).dropna()\r\n",
    "# TODO: need to understend why it not average \r\n",
    "analysis_format_calculeted['Energy_Balance'] = analysis_format_calculeted['actual_foodupa'].values - analysis_format_calculeted['kcal_hr'].values\r\n",
    "\r\n",
    "display(analysis_format.head(2), analysis_format.shape)\r\n",
    "display(resampled_analysis_format.head(2), resampled_analysis_format.shape)\r\n",
    "display(analysis_format_calculeted.head(2), analysis_format_calculeted.shape)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'incal_create_groups_column' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21460/1374986907.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# analysis format - with original datetime samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mincal_create_groups_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresampled_analysis_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_groups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'subjectID'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mresampled_analysis_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mincal_set_multindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresampled_analysis_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Date_Time_1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'subjectID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Group'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# analysis format - datetime agg hor each rol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'incal_create_groups_column' is not defined"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 723
    },
    "id": "62084c58-7ddd-44c3-a451-8e31add5f4da",
    "outputId": "c76d290d-4d76-440f-97d8-8045685a38e8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Dashboard**"
   ],
   "metadata": {
    "id": "b9d05f0d-5da3-4856-84bd-8fcdd2c482b0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def assemble_dash_table(dff):\r\n",
    "    return {\r\n",
    "        'columns': [{\"name\": i, \"id\": i} for i in dff.columns],\r\n",
    "        'data': dff.to_dict('records')\r\n",
    "    }\r\n",
    "\r\n",
    "def get_start_and_end_time(tuple_start_end, dict_time_stamps):\r\n",
    "    start, end = (str(i) for i in tuple_start_end)\r\n",
    "    return dict_time_stamps[start], dict_time_stamps[end]\r\n",
    "\r\n",
    "def get_data(__global_df__, categories_columns_names):\r\n",
    "    # need to find solution to the use of global var\r\n",
    "    time_series = __global_df__.reset_index(level=categories_columns_names)\r\n",
    "    order_categoreis_columns(time_series, subjectID=dict_groups.values(), Group=dict_groups.keys())\r\n",
    "    return time_series\r\n",
    "\r\n",
    "def trim_df_datetime(df, start_time, end_time):\r\n",
    "    return df.loc[start_time:end_time]\r\n",
    "\r\n",
    "def remove_data(df, outliers_true, start_time, end_time):\r\n",
    "    if not outliers_true:\r\n",
    "        return trim_df_datetime(df, start_time, end_time)        \r\n",
    "    outliers_removed = remove_outliers_mixed_df(df, 'subjectID')\r\n",
    "    return trim_df_datetime(outliers_removed, start_time, end_time).dropna()\r\n",
    "\r\n",
    "def get_ready_data_for_analysis(df, categories_columns_names, outliers_true, start_time, end_time):\r\n",
    "    time_series = get_data(df, categories_columns_names).copy()\r\n",
    "    return remove_data(time_series, outliers_true, start_time, end_time)\r\n",
    "\r\n",
    "def assemble_data_to_dom(df, category_name, feature_name):\r\n",
    "    features = [category_name, feature_name, 'bodymass'] if feature_name is 'bodymass' else [category_name, feature_name]\r\n",
    "    return df.loc[:, features]\r\n",
    "\r\n",
    "def get_group_or_individual_df(df, category_name, feature_calc):\r\n",
    "    time_series_group_or_individual_dfs = {\r\n",
    "        'Group': df.groupby([df.index, category_name]).agg(feature_calc).reset_index(1),\r\n",
    "        'subjectID': df\r\n",
    "        }\r\n",
    "    return time_series_group_or_individual_dfs[category_name]\r\n",
    "\r\n",
    "def graphs_maker(clean_df, df_grouped, group_or_individual_df_averages, averages_df, feature_name, category_name, colors):\r\n",
    "    time_series_graph = px.scatter(\r\n",
    "        df_grouped,\r\n",
    "        x=df_grouped.index,\r\n",
    "        y=feature_name,\r\n",
    "        color=category_name, \r\n",
    "        color_discrete_sequence=colors, \r\n",
    "        template='simple_white'\r\n",
    "    ).update_traces(mode='lines+markers')\r\n",
    "\r\n",
    "    histogram = px.histogram(\r\n",
    "        df_grouped, \r\n",
    "        x=feature_name, \r\n",
    "        color=category_name, \r\n",
    "        color_discrete_sequence=colors,\r\n",
    "        template='simple_white'\r\n",
    "        )\r\n",
    "\r\n",
    "    box = px.box(\r\n",
    "        df_grouped,\r\n",
    "        x=category_name,\r\n",
    "        y=feature_name,\r\n",
    "        color=category_name,\r\n",
    "        color_discrete_sequence=colors,\r\n",
    "        template='simple_white'\r\n",
    "        )\r\n",
    "    \r\n",
    "    averages = px.bar(\r\n",
    "        group_or_individual_df_averages,\r\n",
    "        x=category_name,\r\n",
    "        y=feature_name,\r\n",
    "        color=category_name,\r\n",
    "        color_discrete_sequence=colors, \r\n",
    "        template='simple_white'\r\n",
    "    )\r\n",
    "    regression = px.scatter(\r\n",
    "        averages_df,\r\n",
    "        x=averages_df['bodymass'],\r\n",
    "        y=feature_name,\r\n",
    "        color='Group',\r\n",
    "        color_discrete_sequence=colors, \r\n",
    "        template='simple_white', \r\n",
    "        trendline='ols'\r\n",
    "    )  \r\n",
    "    return time_series_graph, histogram, box, averages, regression"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<>:31: SyntaxWarning:\n",
      "\n",
      "\"is\" with a literal. Did you mean \"==\"?\n",
      "\n",
      "<>:31: SyntaxWarning:\n",
      "\n",
      "\"is\" with a literal. Did you mean \"==\"?\n",
      "\n",
      "C:\\Users\\misha\\AppData\\Local\\Temp/ipykernel_15720/1773577836.py:31: SyntaxWarning:\n",
      "\n",
      "\"is\" with a literal. Did you mean \"==\"?\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# STYLE =   {\r\n",
    "#     'overflow': 'hidden',\r\n",
    "#     'background-color': '#333',\r\n",
    "#     'position': 'fixed',\r\n",
    "#     'top': 0,\r\n",
    "#     'width': '100%'\r\n",
    "#   }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# dashboard code. \r\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\r\n",
    "app = JupyterDash(__name__, external_stylesheets = external_stylesheets)\r\n",
    "\r\n",
    "time_stamps = analysis_format_indexed.index.get_level_values(0)\r\n",
    "shape_analysis_format_indexed = analysis_format_indexed.shape\r\n",
    "end_point_index_analysis_format_indexed = shape_analysis_format_indexed[0]-1\r\n",
    "marks_indexed_time_stamp = {i: time_stamps[i] for i in range(shape_analysis_format_indexed[0])}\r\n",
    "\r\n",
    "list_of_featuers = analysis_format_indexed.columns\r\n",
    "categories_columns_names = get_categories_cals_names(analysis_format_indexed)\r\n",
    "obj_categories_columns_names = [{'label': feature, 'value': feature} for feature in categories_columns_names]\r\n",
    "obj_features = [{'label': feature, 'value': feature} for feature in list_of_featuers]\r\n",
    "\r\n",
    "subjects = analysis_format_indexed.index.get_level_values(1).unique()\r\n",
    "groups = analysis_format_indexed.index.get_level_values(2).unique()\r\n",
    "multi_selection_subjects = [{'label': str(subject), 'value': str(subject)} for subject in subjects]\r\n",
    "multi_selection_groups = [{'label': str(group), 'value': str(group)} for group in groups]\r\n",
    "\r\n",
    "app.layout = html.Div(children=[\r\n",
    "    dcc.Dropdown(\r\n",
    "        id='show_as_group_or_individual',\r\n",
    "        options=obj_categories_columns_names,\r\n",
    "        value=categories_columns_names[0]\r\n",
    "    ), \r\n",
    "    dcc.Dropdown(\r\n",
    "        id='feature_exp',\r\n",
    "        options=obj_features,\r\n",
    "        value=list_of_featuers[1]\r\n",
    "    ),\r\n",
    "    dcc.Checklist(\r\n",
    "    id='checklist_remove_outliers',\r\n",
    "    options=[\r\n",
    "        {'label': 'Remove outliers', 'value': 'True'},\r\n",
    "    ],\r\n",
    "    value=[],\r\n",
    "    labelStyle={'display': 'inline-block'}\r\n",
    "    ),\r\n",
    "    dcc.RangeSlider(\r\n",
    "        marks=marks_indexed_time_stamp,\r\n",
    "        value=(0, end_point_index_analysis_format_indexed),\r\n",
    "        id=\"range_slider_time_series\", \r\n",
    "        allowCross=False,\r\n",
    "        min=0,\r\n",
    "        max=end_point_index_analysis_format_indexed,\r\n",
    "    ),\r\n",
    "    dcc.Dropdown(\r\n",
    "        id='remove_group',\r\n",
    "        options=multi_selection_groups,\r\n",
    "        multi=True\r\n",
    "    ), \r\n",
    "    dcc.Dropdown(\r\n",
    "        id='remove_subjects',\r\n",
    "        options=multi_selection_subjects,\r\n",
    "        multi=True\r\n",
    "    ), \r\n",
    "    dcc.Graph(id = 'graph_time_series'), \r\n",
    "    dcc.Graph(id = 'box_graph'), \r\n",
    "    dcc.Graph(id = 'histogram_graph'), \r\n",
    "    dcc.Graph(id = 'graph_averages'), \r\n",
    "    dcc.Graph(id = 'graph_regression'), \r\n",
    "    dash_table.DataTable(id = 'p_values_table')\r\n",
    "])\r\n",
    "\r\n",
    "@app.callback(\r\n",
    "    Output('graph_time_series', 'figure'), \r\n",
    "    Output('box_graph', 'figure'), \r\n",
    "    Output('histogram_graph', 'figure'), \r\n",
    "    Output('graph_averages', 'figure'), \r\n",
    "    Output('graph_regression', 'figure'), \r\n",
    "    Output('p_values_table', 'columns'), \r\n",
    "    Output('p_values_table', 'data'), \r\n",
    "    Input('feature_exp', 'value'),\r\n",
    "    Input('show_as_group_or_individual', 'value'),\r\n",
    "    Input('remove_group', 'value'),\r\n",
    "    Input('remove_subjects', 'value'),\r\n",
    "    Input('checklist_remove_outliers', 'value'),\r\n",
    "    Input('range_slider_time_series', 'value'), \r\n",
    "    Input('range_slider_time_series', 'marks')\r\n",
    ")\r\n",
    "def pool_data(feature_name, category_name, remove_group, remove_subjects, outliers_true, tuple_start_end, dict_time_stamps):\r\n",
    "    start_time, end_time = get_start_and_end_time(tuple_start_end, dict_time_stamps)\r\n",
    "    # analsysis of expriment data - outliers and acclimetion\r\n",
    "    data = analysis_format_indexed.copy()\r\n",
    "    \r\n",
    "    if remove_group:\r\n",
    "        data = incal_remove_group(data, 2, remove_group)\r\n",
    "    if remove_subjects:\r\n",
    "        data = incal_remove_subjects(data, 1, remove_subjects)\r\n",
    "    \r\n",
    "    clean_df = get_ready_data_for_analysis(\r\n",
    "        data, \r\n",
    "        categories_columns_names, \r\n",
    "        outliers_true, \r\n",
    "        start_time, \r\n",
    "        end_time\r\n",
    "        )\r\n",
    "    # data to dom\r\n",
    "    data_for_view = assemble_data_to_dom(clean_df, category_name, feature_name)\r\n",
    "    # time series\r\n",
    "    feature_calc = add_feature_for_agg[feature_name]\r\n",
    "    df_grouped = get_group_or_individual_df(data_for_view, category_name, feature_calc)\r\n",
    "    # averages\r\n",
    "    group_or_individual_df_averages = data_for_view.groupby([category_name]).agg(feature_calc).reset_index()\r\n",
    "    # regression\r\n",
    "    averages_df = clean_df.groupby(categories_columns_names).agg(add_feature_for_agg).dropna().reset_index()\r\n",
    "    # make graphs\r\n",
    "    colors = px.colors.qualitative.Vivid\r\n",
    "    time_series_graph, histogram, box, averages, regression = graphs_maker(\r\n",
    "        clean_df,\r\n",
    "        df_grouped,\r\n",
    "        group_or_individual_df_averages, \r\n",
    "        averages_df, \r\n",
    "        feature_name, \r\n",
    "        category_name, \r\n",
    "        colors\r\n",
    "        )\r\n",
    "    # need to refactore that remove the side affect of in this function \r\n",
    "    grouped_analysis_format_df = clean_df.groupby(categories_columns_names)\r\n",
    "    analysis_format_calculeted = grouped_analysis_format_df.agg(add_feature_for_agg).dropna()\r\n",
    "    analysis_format_calculeted['Energy_Balance'] = analysis_format_calculeted['actual_foodupa'].values - analysis_format_calculeted['kcal_hr'].values\r\n",
    "    analysis_format_calculeted_index_reseted = analysis_format_calculeted.reset_index()\r\n",
    "    p_values_table = create_anovas_table(analysis_format_calculeted_index_reseted)\r\n",
    "    p_values_table = p_values_table.reset_index().rename(columns={'index':'Features'})\r\n",
    "    columns = [{'id': p, 'name': p} for p in p_values_table.columns.to_list()]\r\n",
    "    return time_series_graph, box, histogram, averages, regression, columns, p_values_table.to_dict('records')"
   ],
   "outputs": [],
   "metadata": {
    "id": "2c1d0a12-4fb3-424c-971f-faae6abcc719"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def run_server(self,\r\n",
    "               port=8004,\r\n",
    "               debug=True,\r\n",
    "               threaded=True,\r\n",
    "               **flask_run_options):\r\n",
    "    self.server.run(port=port, debug=debug, **flask_run_options)\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    app.run_server(debug=True, port=8024, mode='external')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\Users\\misha\\Desktop\\Projects\\InCal\\venv\\lib\\site-packages\\jupyter_dash\\jupyter_app.py:139: UserWarning:\n",
      "\n",
      "The 'environ['werkzeug.server.shutdown']' function is deprecated and will be removed in Werkzeug 2.1.\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dash app running on http://127.0.0.1:8024/\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "N6R7FmDICrp-",
    "outputId": "305af7a0-2c6b-4282-8bba-e4a47819dd18"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# http://127.0.0.1:8024/"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_data(__global_df__, categories_columns_names):\r\n",
    "    # need to find solution to the use of global var\r\n",
    "    time_series = __global_df__.reset_index(level=categories_columns_names)\r\n",
    "    order_categoreis_columns(time_series, subjectID=dict_groups.values(), Group=dict_groups.keys())\r\n",
    "    return time_series\r\n",
    "\r\n",
    "def trim_df_datetime(df, start_time, end_time):\r\n",
    "    return df.loc[start_time:end_time]\r\n",
    "\r\n",
    "def remove_data(df, outliers_true, start_time, end_time):\r\n",
    "    if not outliers_true:\r\n",
    "        return trim_df_datetime(df, start_time, end_time)        \r\n",
    "    outliers_removed = remove_outliers_mixed_df(df, 'subjectID')\r\n",
    "    return trim_df_datetime(outliers_removed, start_time, end_time).dropna()\r\n",
    "\r\n",
    "#  removing subjects or group\r\n",
    "def get_values_level(df, number_or_index_name):\r\n",
    "  return df.index.get_level_values(number_or_index_name)\r\n",
    "\r\n",
    "def get_difference_from_list_2(list1, list2):\r\n",
    "    return list(set(list1) - set(list2))\r\n",
    "\r\n",
    "def incal_remove_subjects(df, number_or_index_name, subjects_to_remove):\r\n",
    "  subjects = get_values_level(df, number_or_index_name)\r\n",
    "  strs_to_ints = lambda l: [int(x) for x in l]\r\n",
    "  subjects_to_remove_ints = strs_to_ints(subjects_to_remove)\r\n",
    "  selected_subjects = get_difference_from_list_2(subjects, subjects_to_remove_ints)\r\n",
    "  return df.loc[:, selected_subjects , :]\r\n",
    "\r\n",
    "def incal_remove_group(df, number_or_index_name, groups_to_remove):\r\n",
    "  subjects = get_values_level(df, number_or_index_name)\r\n",
    "  selected_group = get_difference_from_list_2(subjects, groups_to_remove)\r\n",
    "  return df.loc[:, : , selected_group]\r\n",
    "\r\n",
    "# removing outliears\r\n",
    "def sort_data_by_ids(df, column_name):\r\n",
    "    return df.sort_values(column_name)\r\n",
    "\r\n",
    "def flat_list(d_list):\r\n",
    "    '''\r\n",
    "    dependencies: itertools\r\n",
    "    '''\r\n",
    "    return list(itertools.chain.from_iterable(d_list))\r\n",
    "\r\n",
    "def slice_df_for_floats_and_category(df, column_name):\r\n",
    "    return df.select_dtypes(include=['float64']), df.select_dtypes(include=['category'])\r\n",
    "\r\n",
    "def get_subject_ids(df, column_name):\r\n",
    "    return df[column_name].unique()\r\n",
    "\r\n",
    "def calc_mean_and_std_for_df_by_ids(df, ids_column_name):\r\n",
    "    return df.groupby(ids_column_name).agg([np.mean, np.std])\r\n",
    "\r\n",
    "def get_lims_upper_and_lower(df_means_and_stds, number_of_ids, number_featuers_columns, by_sd_of=2):\r\n",
    "    calcs_shape_values = df_means_and_stds.values.reshape(number_of_ids, number_featuers_columns, 2)\r\n",
    "    means = calcs_shape_values[:, :, :1]\r\n",
    "    stds = calcs_shape_values[:, :, 1:]\r\n",
    "    upper_lims = means + stds * by_sd_of\r\n",
    "    lower_lims = means - stds * by_sd_of\r\n",
    "    return upper_lims, lower_lims\r\n",
    "\r\n",
    "def reshpe_vlaues_3d_ndarray(ndarray, axis0_dimensions, axis1_columns, axis2_rows):\r\n",
    "    return ndarray.reshape(axis0_dimensions, axis1_columns, axis2_rows)\r\n",
    "\r\n",
    "def select_and_replace_outliers(ndarry_of_features, ndarry_uppers_lims, ndarry_lowers_lims):\r\n",
    "    conditiones = [\r\n",
    "        ndarry_of_features > ndarry_uppers_lims,\r\n",
    "        ndarry_of_features < ndarry_lowers_lims\r\n",
    "    ]\r\n",
    "    choices = [np.nan, np.nan]\r\n",
    "    return np.select(conditiones, choices, ndarry_of_features)\r\n",
    "    \r\n",
    "def back_to_2d_ndarray(ndarry_of_features, axis1, axis2):\r\n",
    "    return ndarry_of_features.reshape(axis1, axis2)\r\n",
    "    \r\n",
    "def sort_data_by_index(df):\r\n",
    "    return df.sort_index()\r\n",
    "\r\n",
    "def get_categories_cals_names(df):\r\n",
    "    return df.index.names[1:] \r\n",
    "\r\n",
    "def incal_get_categories_col_from_multiindex(df):\r\n",
    "  levels_names = get_categories_cals_names(df)\r\n",
    "  get_values_values_from_index = df.reset_index(level=levels_names)\r\n",
    "  return get_values_values_from_index[levels_names]\r\n",
    "\r\n",
    "def remove_outliers_mixed_df(features_values, column_ids_values):\r\n",
    "    # sort by id \r\n",
    "    sorted_df = sort_data_by_ids(df, column_ids_name)\r\n",
    "    # fetuers, ids = slice_df_for_floats_and_category(sorted_df, column_ids_name)\r\n",
    "    df_means_and_stds = calc_mean_and_std_for_df_by_ids(fetuers, ids[column_ids_name])\r\n",
    "    number_of_ids = len(ids[column_ids_name].unique())\r\n",
    "    fetuers_columns = fetuers.columns\r\n",
    "    number_featuers_columns = len(fetuers_columns)\r\n",
    "    upper_lims, lower_lims = get_lims_upper_and_lower(df_means_and_stds, number_of_ids, number_featuers_columns)\r\n",
    "    dimensions_by_numbers_of_ids_upper_lims = reshpe_vlaues_3d_ndarray(upper_lims, number_of_ids, 1, number_featuers_columns) \r\n",
    "    dimensions_by_numbers_of_ids_lower_lims = reshpe_vlaues_3d_ndarray(lower_lims, number_of_ids, 1, number_featuers_columns)\r\n",
    "    columns_of_each_id = fetuers.shape[0] // number_of_ids\r\n",
    "    dimensions_by_numbers_of_ids_values = reshpe_vlaues_3d_ndarray(\r\n",
    "        fetuers.values, \r\n",
    "        number_of_ids, \r\n",
    "        columns_of_each_id, \r\n",
    "        number_featuers_columns\r\n",
    "    )\r\n",
    "    outliers_replaced_to_nan_values_ndarray = select_and_replace_outliers(\r\n",
    "        dimensions_by_numbers_of_ids_values, \r\n",
    "        dimensions_by_numbers_of_ids_upper_lims, \r\n",
    "        dimensions_by_numbers_of_ids_lower_lims\r\n",
    "        )\r\n",
    "    combien_axis0_and_axis1 = number_of_ids * columns_of_each_id\r\n",
    "    original_df_shape = back_to_2d_ndarray(outliers_replaced_to_nan_values_ndarray, combien_axis0_and_axis1, number_featuers_columns)\r\n",
    "    df_fetuers_without_outliers = pd.DataFrame(original_df_shape, columns=fetuers_columns, index=ids.index)\r\n",
    "    df_without_outliers = pd.concat([ids, df_fetuers_without_outliers], axis=1)\r\n",
    "    return sort_data_by_index(df_without_outliers)\r\n",
    "\r\n",
    "def incal_set_multindex(df, list_of_multi_index, drop_current_index=False):\r\n",
    "  ids_indexed_df = df.reset_index(drop=drop_current_index)\r\n",
    "  return ids_indexed_df.set_index(list_of_multi_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "# removing data logic application \r\n",
    "incal_format = pd.read_csv('csvs/analysis_format.csv', index_col=False)\r\n",
    "# time_series = get_data(analysis_format_indexed, categories_columns_names).copy()\r\n",
    "# clean_df = remove_data(time_series, False, marks_indexed_time_stamp[0], marks_indexed_time_stamp[999])\r\n",
    "# incal_set_multindex(incal_format, ['Date_Time_1', 'subjectID', 'Group'], True)\r\n",
    "# dict_groups\r\n",
    "\r\n",
    "# subjects = get_subject_ids(incal_format, ids_column_name)\r\n",
    "\r\n",
    "def create_category_column(df , categories, ordered=True):\r\n",
    "    '''\r\n",
    "    order_categoreis_columns make sure the group and subjects in the right order. This is for,\r\n",
    "    the statiscal analysis. The groups and the subjects needs to be in order of the expriment design.\r\n",
    "    In order the anova, ancova and anova with interaction to work properly\r\n",
    "    \r\n",
    "    '''\r\n",
    "    return pd.Categorical(df, categories=categories, ordered=True)\r\n",
    "\r\n",
    "def replace_ids_to_group_id(ndarray_ids, groups_names, subjects_within_group):\r\n",
    "  conditiones = [ndarray_ids == n for n in subjects_within_group]\r\n",
    "  choices = groups_names\r\n",
    "  return np.select(conditiones, choices, ndarray_ids)\r\n",
    "\r\n",
    "def incal_create_group_column_from_ids(df, ids_column_name, dict_groups):\r\n",
    "  n_ids_multiple_name = lambda name, n: [name] * len(n)\r\n",
    "  subjects_vlaues = incal_format[ids_column_name].values\r\n",
    "  items = dict_groups.items()\r\n",
    "  groups_names = flat_list([n_ids_multiple_name(group, ids) for group, ids in items])\r\n",
    "  subjects_within_groups = flat_list([ids for ids in dict_groups.values()])\r\n",
    "  return replace_ids_to_group_id(subjects_vlaues, groups_names, subjects_within_groups)\r\n",
    "\r\n",
    "def incal_assemble_group_column_in_df(\r\n",
    "    df, \r\n",
    "    ids_column_name, \r\n",
    "    dict_groups, \r\n",
    "    group_column_name):\r\n",
    "  values = incal_create_group_column_from_ids(df, ids_column_name, dict_groups)\r\n",
    "  series = pd.Series(values,  copy=False, name=group_column_name)\r\n",
    "  return concat_dfs([incal_format, series])\r\n",
    "\r\n",
    "def get_incal_levels_properties(dict_groups):\r\n",
    "  date_time_type = 'datetime64[ns]'\r\n",
    "  order_subjects = flat_list(dict_groups.values())\r\n",
    "  order_groups = list(dict_groups.keys())\r\n",
    "  return date_time_type, order_subjects, order_groups\r\n",
    "\r\n",
    "def design_incal_levels(idx0, idx1, idx2, date_time_type, order_subjects, order_groups):\r\n",
    "  level_0 = idx0.astype(date_time_type) #level 0 convert to type of date time   \r\n",
    "  level_1 = create_category_column(idx1, order_subjects) #level 0 convert to type of date time   \r\n",
    "  level_2 = create_category_column(idx2, order_groups) #level 0 convert to type of date time   \r\n",
    "  return level_0, level_1, level_2\r\n",
    "\r\n",
    "def incal_create_levels(df, dict_groups):\r\n",
    "  date_time_type, order_subjects, order_groups = get_incal_levels_properties(dict_groups)\r\n",
    "  idx = df.index\r\n",
    "  l0, l1, l2 = design_incal_levels(idx.levels[0], idx.levels[1], idx.levels[2], date_time_type, order_subjects, order_groups)\r\n",
    "  return df.index.set_levels([l0, l1, l2])\r\n",
    "\r\n",
    "\r\n",
    "incal_df = incal_assemble_group_column_in_df(incal_format, 'subjectID', dict_groups, 'Group')\r\n",
    "incal_format_df = incal_df.set_index(['Date_Time_1', 'subjectID', 'Group']).copy()\r\n",
    "# https://stackoverflow.com/questions/34417970/pandas-convert-index-type-in-multiindex-dataframe\r\n",
    "incal_format_df.index = incal_create_levels(incal_format_df, dict_groups)\r\n",
    "incal_formated_df = incal_format_df.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "# remove outliears\r\n",
    "remove_outliers_mixed_df()\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "levels_ids, levels_uniques = levels_as_ids.factorize()\r\n",
    "columns_names = _get_columns_names_list(incal_formated_df)\r\n",
    "id_level = levels_uniques[0]\r\n",
    "id_column = columns_names[2]\r\n",
    "\r\n",
    "# remove specific value\r\n",
    "def remove_specific_value_at(df, list_of_level_id_with_column_id):\r\n",
    "  for level,  column in list_of_level_id_with_column_id:\r\n",
    "    incal_formated_df.at[level, column] = np.nan\r\n",
    "remove_specific_value_at(df, [id_level, id_column])\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Energy_Balance</th>\n",
       "      <th>actual_allmeters</th>\n",
       "      <th>actual_allmeters_cumsum</th>\n",
       "      <th>actual_foodupa</th>\n",
       "      <th>actual_pedmeters</th>\n",
       "      <th>actual_pedmeters_cumsum</th>\n",
       "      <th>actual_waterupa</th>\n",
       "      <th>bodymass</th>\n",
       "      <th>envirolightlux</th>\n",
       "      <th>envirooccupancy</th>\n",
       "      <th>...</th>\n",
       "      <th>envirosound</th>\n",
       "      <th>envirotemp</th>\n",
       "      <th>kcal_hr</th>\n",
       "      <th>locomotor_activity</th>\n",
       "      <th>rq</th>\n",
       "      <th>vco2</th>\n",
       "      <th>vh2o</th>\n",
       "      <th>vo2</th>\n",
       "      <th>xbreak</th>\n",
       "      <th>ybreak</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_Time_1</th>\n",
       "      <th>subjectID</th>\n",
       "      <th>Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021-07-28 16:45:00</th>\n",
       "      <th>1</th>\n",
       "      <th>Control</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259127</td>\n",
       "      <td>0.259127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.46564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.407835</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.758679</td>\n",
       "      <td>64.866900</td>\n",
       "      <td>8.167320</td>\n",
       "      <td>85.280940</td>\n",
       "      <td>79.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>Control</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.404414</td>\n",
       "      <td>0.313275</td>\n",
       "      <td>1.140263</td>\n",
       "      <td>1.140263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.61497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.401331</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.818524</td>\n",
       "      <td>67.938600</td>\n",
       "      <td>9.748566</td>\n",
       "      <td>82.768560</td>\n",
       "      <td>64.0</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>Group_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.553978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>3.171110</td>\n",
       "      <td>3.171110</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>21.34998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.383572</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.794086</td>\n",
       "      <td>63.289920</td>\n",
       "      <td>8.856168</td>\n",
       "      <td>79.566900</td>\n",
       "      <td>150.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>Group_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11.915580</td>\n",
       "      <td>11.915580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.116600</td>\n",
       "      <td>11.116600</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>24.69681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.366636</td>\n",
       "      <td>788.0</td>\n",
       "      <td>0.843458</td>\n",
       "      <td>63.434640</td>\n",
       "      <td>7.688532</td>\n",
       "      <td>75.228840</td>\n",
       "      <td>191.0</td>\n",
       "      <td>597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>Control</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.425906</td>\n",
       "      <td>3.425906</td>\n",
       "      <td>0.116263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.752747</td>\n",
       "      <td>0.077571</td>\n",
       "      <td>25.82226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454166</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.772627</td>\n",
       "      <td>73.195680</td>\n",
       "      <td>8.843118</td>\n",
       "      <td>94.699680</td>\n",
       "      <td>11.0</td>\n",
       "      <td>429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021-08-01 13:05:00</th>\n",
       "      <th>5</th>\n",
       "      <th>Group_2</th>\n",
       "      <td>-0.397047</td>\n",
       "      <td>2.634100</td>\n",
       "      <td>495.190900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.736800</td>\n",
       "      <td>350.239900</td>\n",
       "      <td>0.042690</td>\n",
       "      <td>22.32520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.397047</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>66.486420</td>\n",
       "      <td>4.813436</td>\n",
       "      <td>82.089180</td>\n",
       "      <td>36.0</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>Group_3</th>\n",
       "      <td>-0.404414</td>\n",
       "      <td>1.922600</td>\n",
       "      <td>607.548300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.308400</td>\n",
       "      <td>419.765200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.20752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.404414</td>\n",
       "      <td>395.0</td>\n",
       "      <td>0.787974</td>\n",
       "      <td>66.352440</td>\n",
       "      <td>5.814180</td>\n",
       "      <td>83.995860</td>\n",
       "      <td>181.0</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>Control</th>\n",
       "      <td>0.155503</td>\n",
       "      <td>0.898600</td>\n",
       "      <td>492.712600</td>\n",
       "      <td>0.548347</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>336.268900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.83795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.392844</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.834081</td>\n",
       "      <td>67.201680</td>\n",
       "      <td>5.160598</td>\n",
       "      <td>80.821920</td>\n",
       "      <td>99.0</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>Group_3</th>\n",
       "      <td>-0.263771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>635.210900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>542.285900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.16039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.263771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.712551</td>\n",
       "      <td>39.750744</td>\n",
       "      <td>4.997085</td>\n",
       "      <td>55.774272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>Group_2</th>\n",
       "      <td>-0.314500</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>648.265900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>469.407600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.66077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.314500</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.674944</td>\n",
       "      <td>45.282120</td>\n",
       "      <td>6.408408</td>\n",
       "      <td>67.094220</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4448 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Energy_Balance  actual_allmeters  \\\n",
       "Date_Time_1         subjectID Group                                       \n",
       "2021-07-28 16:45:00 1         Control             NaN          0.820163   \n",
       "                    10        Control             NaN               NaN   \n",
       "                    11        Group_3             NaN          3.553978   \n",
       "                    12        Group_2             NaN         11.915580   \n",
       "                    13        Control             NaN          3.425906   \n",
       "...                                               ...               ...   \n",
       "2021-08-01 13:05:00 5         Group_2       -0.397047          2.634100   \n",
       "                    6         Group_3       -0.404414          1.922600   \n",
       "                    7         Control        0.155503          0.898600   \n",
       "                    8         Group_3       -0.263771          0.000000   \n",
       "                    9         Group_2       -0.314500          0.124100   \n",
       "\n",
       "                                       actual_allmeters_cumsum  \\\n",
       "Date_Time_1         subjectID Group                              \n",
       "2021-07-28 16:45:00 1         Control                 0.820163   \n",
       "                    10        Control                 1.404414   \n",
       "                    11        Group_3                      NaN   \n",
       "                    12        Group_2                11.915580   \n",
       "                    13        Control                 3.425906   \n",
       "...                                                        ...   \n",
       "2021-08-01 13:05:00 5         Group_2               495.190900   \n",
       "                    6         Group_3               607.548300   \n",
       "                    7         Control               492.712600   \n",
       "                    8         Group_3               635.210900   \n",
       "                    9         Group_2               648.265900   \n",
       "\n",
       "                                       actual_foodupa  actual_pedmeters  \\\n",
       "Date_Time_1         subjectID Group                                       \n",
       "2021-07-28 16:45:00 1         Control        0.000000          0.259127   \n",
       "                    10        Control        0.313275          1.140263   \n",
       "                    11        Group_3        0.006243          3.171110   \n",
       "                    12        Group_2             NaN         11.116600   \n",
       "                    13        Control        0.116263               NaN   \n",
       "...                                               ...               ...   \n",
       "2021-08-01 13:05:00 5         Group_2        0.000000          1.736800   \n",
       "                    6         Group_3        0.000000          1.308400   \n",
       "                    7         Control        0.548347          0.372000   \n",
       "                    8         Group_3        0.000000          0.000000   \n",
       "                    9         Group_2        0.000000          0.000000   \n",
       "\n",
       "                                       actual_pedmeters_cumsum  \\\n",
       "Date_Time_1         subjectID Group                              \n",
       "2021-07-28 16:45:00 1         Control                 0.259127   \n",
       "                    10        Control                 1.140263   \n",
       "                    11        Group_3                 3.171110   \n",
       "                    12        Group_2                11.116600   \n",
       "                    13        Control                 2.752747   \n",
       "...                                                        ...   \n",
       "2021-08-01 13:05:00 5         Group_2               350.239900   \n",
       "                    6         Group_3               419.765200   \n",
       "                    7         Control               336.268900   \n",
       "                    8         Group_3               542.285900   \n",
       "                    9         Group_2               469.407600   \n",
       "\n",
       "                                       actual_waterupa  bodymass  \\\n",
       "Date_Time_1         subjectID Group                                \n",
       "2021-07-28 16:45:00 1         Control         0.000000  24.46564   \n",
       "                    10        Control         0.000000  22.61497   \n",
       "                    11        Group_3         0.002538  21.34998   \n",
       "                    12        Group_2         0.001420  24.69681   \n",
       "                    13        Control         0.077571  25.82226   \n",
       "...                                                ...       ...   \n",
       "2021-08-01 13:05:00 5         Group_2         0.042690  22.32520   \n",
       "                    6         Group_3         0.000000  25.20752   \n",
       "                    7         Control         0.000000  23.83795   \n",
       "                    8         Group_3         0.000000  21.16039   \n",
       "                    9         Group_2         0.000000  25.66077   \n",
       "\n",
       "                                       envirolightlux  envirooccupancy  ...  \\\n",
       "Date_Time_1         subjectID Group                                     ...   \n",
       "2021-07-28 16:45:00 1         Control             NaN              NaN  ...   \n",
       "                    10        Control             NaN              NaN  ...   \n",
       "                    11        Group_3             NaN              NaN  ...   \n",
       "                    12        Group_2             NaN              NaN  ...   \n",
       "                    13        Control             NaN              NaN  ...   \n",
       "...                                               ...              ...  ...   \n",
       "2021-08-01 13:05:00 5         Group_2             NaN              NaN  ...   \n",
       "                    6         Group_3             NaN              NaN  ...   \n",
       "                    7         Control             NaN              NaN  ...   \n",
       "                    8         Group_3             NaN              NaN  ...   \n",
       "                    9         Group_2             NaN              NaN  ...   \n",
       "\n",
       "                                       envirosound  envirotemp   kcal_hr  \\\n",
       "Date_Time_1         subjectID Group                                        \n",
       "2021-07-28 16:45:00 1         Control          NaN         NaN  0.407835   \n",
       "                    10        Control          NaN         NaN  0.401331   \n",
       "                    11        Group_3          NaN         NaN  0.383572   \n",
       "                    12        Group_2          NaN         NaN  0.366636   \n",
       "                    13        Control          NaN         NaN  0.454166   \n",
       "...                                            ...         ...       ...   \n",
       "2021-08-01 13:05:00 5         Group_2          NaN         NaN  0.397047   \n",
       "                    6         Group_3          NaN         NaN  0.404414   \n",
       "                    7         Control          NaN         NaN  0.392844   \n",
       "                    8         Group_3          NaN         NaN  0.263771   \n",
       "                    9         Group_2          NaN         NaN  0.314500   \n",
       "\n",
       "                                       locomotor_activity        rq  \\\n",
       "Date_Time_1         subjectID Group                                   \n",
       "2021-07-28 16:45:00 1         Control               201.0  0.758679   \n",
       "                    10        Control               211.0  0.818524   \n",
       "                    11        Group_3               360.0  0.794086   \n",
       "                    12        Group_2               788.0  0.843458   \n",
       "                    13        Control               440.0  0.772627   \n",
       "...                                                   ...       ...   \n",
       "2021-08-01 13:05:00 5         Group_2               220.0  0.809917   \n",
       "                    6         Group_3               395.0  0.787974   \n",
       "                    7         Control               285.0  0.834081   \n",
       "                    8         Group_3                 0.0  0.712551   \n",
       "                    9         Group_2                26.0  0.674944   \n",
       "\n",
       "                                            vco2      vh2o        vo2  xbreak  \\\n",
       "Date_Time_1         subjectID Group                                             \n",
       "2021-07-28 16:45:00 1         Control  64.866900  8.167320  85.280940    79.0   \n",
       "                    10        Control  67.938600  9.748566  82.768560    64.0   \n",
       "                    11        Group_3  63.289920  8.856168  79.566900   150.0   \n",
       "                    12        Group_2  63.434640  7.688532  75.228840   191.0   \n",
       "                    13        Control  73.195680  8.843118  94.699680    11.0   \n",
       "...                                          ...       ...        ...     ...   \n",
       "2021-08-01 13:05:00 5         Group_2  66.486420  4.813436  82.089180    36.0   \n",
       "                    6         Group_3  66.352440  5.814180  83.995860   181.0   \n",
       "                    7         Control  67.201680  5.160598  80.821920    99.0   \n",
       "                    8         Group_3  39.750744  4.997085  55.774272     0.0   \n",
       "                    9         Group_2  45.282120  6.408408  67.094220    14.0   \n",
       "\n",
       "                                       ybreak  \n",
       "Date_Time_1         subjectID Group            \n",
       "2021-07-28 16:45:00 1         Control   122.0  \n",
       "                    10        Control   147.0  \n",
       "                    11        Group_3   210.0  \n",
       "                    12        Group_2   597.0  \n",
       "                    13        Control   429.0  \n",
       "...                                       ...  \n",
       "2021-08-01 13:05:00 5         Group_2   184.0  \n",
       "                    6         Group_3   214.0  \n",
       "                    7         Control   186.0  \n",
       "                    8         Group_3     0.0  \n",
       "                    9         Group_2    12.0  \n",
       "\n",
       "[4448 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "incal_formated_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Energy_Balance</th>\n",
       "      <th>actual_allmeters</th>\n",
       "      <th>actual_allmeters_cumsum</th>\n",
       "      <th>actual_foodupa</th>\n",
       "      <th>actual_pedmeters</th>\n",
       "      <th>actual_pedmeters_cumsum</th>\n",
       "      <th>actual_waterupa</th>\n",
       "      <th>bodymass</th>\n",
       "      <th>envirolightlux</th>\n",
       "      <th>envirooccupancy</th>\n",
       "      <th>...</th>\n",
       "      <th>envirosound</th>\n",
       "      <th>envirotemp</th>\n",
       "      <th>kcal_hr</th>\n",
       "      <th>locomotor_activity</th>\n",
       "      <th>rq</th>\n",
       "      <th>vco2</th>\n",
       "      <th>vh2o</th>\n",
       "      <th>vo2</th>\n",
       "      <th>xbreak</th>\n",
       "      <th>ybreak</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_Time_1</th>\n",
       "      <th>subjectID</th>\n",
       "      <th>Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021-07-28 16:45:00</th>\n",
       "      <th>1</th>\n",
       "      <th>Control</th>\n",
       "      <td>-0.407835</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259127</td>\n",
       "      <td>0.259127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.46564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.407835</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.758679</td>\n",
       "      <td>64.866900</td>\n",
       "      <td>8.167320</td>\n",
       "      <td>85.280940</td>\n",
       "      <td>79.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>Control</th>\n",
       "      <td>-0.088056</td>\n",
       "      <td>1.404414</td>\n",
       "      <td>1.404414</td>\n",
       "      <td>0.313275</td>\n",
       "      <td>1.140263</td>\n",
       "      <td>1.140263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.61497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.401331</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.818524</td>\n",
       "      <td>67.938600</td>\n",
       "      <td>9.748566</td>\n",
       "      <td>82.768560</td>\n",
       "      <td>64.0</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>Group_3</th>\n",
       "      <td>-0.377329</td>\n",
       "      <td>3.553978</td>\n",
       "      <td>3.553978</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>3.171110</td>\n",
       "      <td>3.171110</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>21.34998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.383572</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.794086</td>\n",
       "      <td>63.289920</td>\n",
       "      <td>8.856168</td>\n",
       "      <td>79.566900</td>\n",
       "      <td>150.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>Group_2</th>\n",
       "      <td>-0.162136</td>\n",
       "      <td>11.915580</td>\n",
       "      <td>11.915580</td>\n",
       "      <td>0.204500</td>\n",
       "      <td>11.116600</td>\n",
       "      <td>11.116600</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>24.69681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.366636</td>\n",
       "      <td>788.0</td>\n",
       "      <td>0.843458</td>\n",
       "      <td>63.434640</td>\n",
       "      <td>7.688532</td>\n",
       "      <td>75.228840</td>\n",
       "      <td>191.0</td>\n",
       "      <td>597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>Control</th>\n",
       "      <td>-0.337903</td>\n",
       "      <td>3.425906</td>\n",
       "      <td>3.425906</td>\n",
       "      <td>0.116263</td>\n",
       "      <td>2.752747</td>\n",
       "      <td>2.752747</td>\n",
       "      <td>0.077571</td>\n",
       "      <td>25.82226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454166</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.772627</td>\n",
       "      <td>73.195680</td>\n",
       "      <td>8.843118</td>\n",
       "      <td>94.699680</td>\n",
       "      <td>11.0</td>\n",
       "      <td>429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021-08-01 13:05:00</th>\n",
       "      <th>5</th>\n",
       "      <th>Group_2</th>\n",
       "      <td>-0.397047</td>\n",
       "      <td>2.634100</td>\n",
       "      <td>495.190900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.736800</td>\n",
       "      <td>350.239900</td>\n",
       "      <td>0.042690</td>\n",
       "      <td>22.32520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.397047</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>66.486420</td>\n",
       "      <td>4.813436</td>\n",
       "      <td>82.089180</td>\n",
       "      <td>36.0</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>Group_3</th>\n",
       "      <td>-0.404414</td>\n",
       "      <td>1.922600</td>\n",
       "      <td>607.548300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.308400</td>\n",
       "      <td>419.765200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.20752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.404414</td>\n",
       "      <td>395.0</td>\n",
       "      <td>0.787974</td>\n",
       "      <td>66.352440</td>\n",
       "      <td>5.814180</td>\n",
       "      <td>83.995860</td>\n",
       "      <td>181.0</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>Control</th>\n",
       "      <td>0.155503</td>\n",
       "      <td>0.898600</td>\n",
       "      <td>492.712600</td>\n",
       "      <td>0.548347</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>336.268900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.83795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.392844</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.834081</td>\n",
       "      <td>67.201680</td>\n",
       "      <td>5.160598</td>\n",
       "      <td>80.821920</td>\n",
       "      <td>99.0</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>Group_3</th>\n",
       "      <td>-0.263771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>635.210900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>542.285900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.16039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.263771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.712551</td>\n",
       "      <td>39.750744</td>\n",
       "      <td>4.997085</td>\n",
       "      <td>55.774272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>Group_2</th>\n",
       "      <td>-0.314500</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>648.265900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>469.407600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.66077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.314500</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.674944</td>\n",
       "      <td>45.282120</td>\n",
       "      <td>6.408408</td>\n",
       "      <td>67.094220</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4448 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Energy_Balance  actual_allmeters  \\\n",
       "Date_Time_1         subjectID Group                                       \n",
       "2021-07-28 16:45:00 1         Control       -0.407835          0.820163   \n",
       "                    10        Control       -0.088056          1.404414   \n",
       "                    11        Group_3       -0.377329          3.553978   \n",
       "                    12        Group_2       -0.162136         11.915580   \n",
       "                    13        Control       -0.337903          3.425906   \n",
       "...                                               ...               ...   \n",
       "2021-08-01 13:05:00 5         Group_2       -0.397047          2.634100   \n",
       "                    6         Group_3       -0.404414          1.922600   \n",
       "                    7         Control        0.155503          0.898600   \n",
       "                    8         Group_3       -0.263771          0.000000   \n",
       "                    9         Group_2       -0.314500          0.124100   \n",
       "\n",
       "                                       actual_allmeters_cumsum  \\\n",
       "Date_Time_1         subjectID Group                              \n",
       "2021-07-28 16:45:00 1         Control                 0.820163   \n",
       "                    10        Control                 1.404414   \n",
       "                    11        Group_3                 3.553978   \n",
       "                    12        Group_2                11.915580   \n",
       "                    13        Control                 3.425906   \n",
       "...                                                        ...   \n",
       "2021-08-01 13:05:00 5         Group_2               495.190900   \n",
       "                    6         Group_3               607.548300   \n",
       "                    7         Control               492.712600   \n",
       "                    8         Group_3               635.210900   \n",
       "                    9         Group_2               648.265900   \n",
       "\n",
       "                                       actual_foodupa  actual_pedmeters  \\\n",
       "Date_Time_1         subjectID Group                                       \n",
       "2021-07-28 16:45:00 1         Control        0.000000          0.259127   \n",
       "                    10        Control        0.313275          1.140263   \n",
       "                    11        Group_3        0.006243          3.171110   \n",
       "                    12        Group_2        0.204500         11.116600   \n",
       "                    13        Control        0.116263          2.752747   \n",
       "...                                               ...               ...   \n",
       "2021-08-01 13:05:00 5         Group_2        0.000000          1.736800   \n",
       "                    6         Group_3        0.000000          1.308400   \n",
       "                    7         Control        0.548347          0.372000   \n",
       "                    8         Group_3        0.000000          0.000000   \n",
       "                    9         Group_2        0.000000          0.000000   \n",
       "\n",
       "                                       actual_pedmeters_cumsum  \\\n",
       "Date_Time_1         subjectID Group                              \n",
       "2021-07-28 16:45:00 1         Control                 0.259127   \n",
       "                    10        Control                 1.140263   \n",
       "                    11        Group_3                 3.171110   \n",
       "                    12        Group_2                11.116600   \n",
       "                    13        Control                 2.752747   \n",
       "...                                                        ...   \n",
       "2021-08-01 13:05:00 5         Group_2               350.239900   \n",
       "                    6         Group_3               419.765200   \n",
       "                    7         Control               336.268900   \n",
       "                    8         Group_3               542.285900   \n",
       "                    9         Group_2               469.407600   \n",
       "\n",
       "                                       actual_waterupa  bodymass  \\\n",
       "Date_Time_1         subjectID Group                                \n",
       "2021-07-28 16:45:00 1         Control         0.000000  24.46564   \n",
       "                    10        Control         0.000000  22.61497   \n",
       "                    11        Group_3         0.002538  21.34998   \n",
       "                    12        Group_2         0.001420  24.69681   \n",
       "                    13        Control         0.077571  25.82226   \n",
       "...                                                ...       ...   \n",
       "2021-08-01 13:05:00 5         Group_2         0.042690  22.32520   \n",
       "                    6         Group_3         0.000000  25.20752   \n",
       "                    7         Control         0.000000  23.83795   \n",
       "                    8         Group_3         0.000000  21.16039   \n",
       "                    9         Group_2         0.000000  25.66077   \n",
       "\n",
       "                                       envirolightlux  envirooccupancy  ...  \\\n",
       "Date_Time_1         subjectID Group                                     ...   \n",
       "2021-07-28 16:45:00 1         Control             NaN              NaN  ...   \n",
       "                    10        Control             NaN              NaN  ...   \n",
       "                    11        Group_3             NaN              NaN  ...   \n",
       "                    12        Group_2             NaN              NaN  ...   \n",
       "                    13        Control             NaN              NaN  ...   \n",
       "...                                               ...              ...  ...   \n",
       "2021-08-01 13:05:00 5         Group_2             NaN              NaN  ...   \n",
       "                    6         Group_3             NaN              NaN  ...   \n",
       "                    7         Control             NaN              NaN  ...   \n",
       "                    8         Group_3             NaN              NaN  ...   \n",
       "                    9         Group_2             NaN              NaN  ...   \n",
       "\n",
       "                                       envirosound  envirotemp   kcal_hr  \\\n",
       "Date_Time_1         subjectID Group                                        \n",
       "2021-07-28 16:45:00 1         Control          NaN         NaN  0.407835   \n",
       "                    10        Control          NaN         NaN  0.401331   \n",
       "                    11        Group_3          NaN         NaN  0.383572   \n",
       "                    12        Group_2          NaN         NaN  0.366636   \n",
       "                    13        Control          NaN         NaN  0.454166   \n",
       "...                                            ...         ...       ...   \n",
       "2021-08-01 13:05:00 5         Group_2          NaN         NaN  0.397047   \n",
       "                    6         Group_3          NaN         NaN  0.404414   \n",
       "                    7         Control          NaN         NaN  0.392844   \n",
       "                    8         Group_3          NaN         NaN  0.263771   \n",
       "                    9         Group_2          NaN         NaN  0.314500   \n",
       "\n",
       "                                       locomotor_activity        rq  \\\n",
       "Date_Time_1         subjectID Group                                   \n",
       "2021-07-28 16:45:00 1         Control               201.0  0.758679   \n",
       "                    10        Control               211.0  0.818524   \n",
       "                    11        Group_3               360.0  0.794086   \n",
       "                    12        Group_2               788.0  0.843458   \n",
       "                    13        Control               440.0  0.772627   \n",
       "...                                                   ...       ...   \n",
       "2021-08-01 13:05:00 5         Group_2               220.0  0.809917   \n",
       "                    6         Group_3               395.0  0.787974   \n",
       "                    7         Control               285.0  0.834081   \n",
       "                    8         Group_3                 0.0  0.712551   \n",
       "                    9         Group_2                26.0  0.674944   \n",
       "\n",
       "                                            vco2      vh2o        vo2  xbreak  \\\n",
       "Date_Time_1         subjectID Group                                             \n",
       "2021-07-28 16:45:00 1         Control  64.866900  8.167320  85.280940    79.0   \n",
       "                    10        Control  67.938600  9.748566  82.768560    64.0   \n",
       "                    11        Group_3  63.289920  8.856168  79.566900   150.0   \n",
       "                    12        Group_2  63.434640  7.688532  75.228840   191.0   \n",
       "                    13        Control  73.195680  8.843118  94.699680    11.0   \n",
       "...                                          ...       ...        ...     ...   \n",
       "2021-08-01 13:05:00 5         Group_2  66.486420  4.813436  82.089180    36.0   \n",
       "                    6         Group_3  66.352440  5.814180  83.995860   181.0   \n",
       "                    7         Control  67.201680  5.160598  80.821920    99.0   \n",
       "                    8         Group_3  39.750744  4.997085  55.774272     0.0   \n",
       "                    9         Group_2  45.282120  6.408408  67.094220    14.0   \n",
       "\n",
       "                                       ybreak  \n",
       "Date_Time_1         subjectID Group            \n",
       "2021-07-28 16:45:00 1         Control   122.0  \n",
       "                    10        Control   147.0  \n",
       "                    11        Group_3   210.0  \n",
       "                    12        Group_2   597.0  \n",
       "                    13        Control   429.0  \n",
       "...                                       ...  \n",
       "2021-08-01 13:05:00 5         Group_2   184.0  \n",
       "                    6         Group_3   214.0  \n",
       "                    7         Control   186.0  \n",
       "                    8         Group_3     0.0  \n",
       "                    9         Group_2    12.0  \n",
       "\n",
       "[4448 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "re = incal_remove_subjects(analysis_format_indexed, 1, [1, 2, 3, 16])\r\n",
    "get_values_level(dfff, 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "level = get_values_level(dfff, 'subjectID')\r\n",
    "level.unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of in-cal-nootbook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('venv': venv)"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "66599a7a6142eae9f63457fbd787ef4b55802012b5e3fbb704210ee6f3bbe423"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}